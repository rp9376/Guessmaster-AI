# GuessMaster 20Q - Environment Configuration Template
# Copy this file to .env and configure your settings

# Configure this to point to your existing Ollama instance
# Examples:
# Local: http://localhost:11434/api/generate  
# Remote: http://your-server-ip:11434/api/generate
# Docker host: http://host.docker.internal:11434/api/generate
OLLAMA_URL=http://localhost:11434/api/generate

# Model name available in your Ollama instance
# Examples: llama3.2, llama3.3:70b, mistral, codellama
OLLAMA_MODEL=llama3.2

# Django settings
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1

# Generate a secure secret key for production
# You can generate one at: https://djecrety.ir/
SECRET_KEY=your-secret-key-here-change-in-production

# Optional: Custom port for the web server (default: 9090)
# WEB_PORT=9090
